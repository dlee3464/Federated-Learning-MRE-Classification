{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/itslastonenikhil/federated-learning/blob/main/FederatedLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DCo8KE2lm_DZ"
   },
   "source": [
    "### Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KOOKNpifmqcx"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
    "# Dataset stores samples and corresponding labels \n",
    "# DataLoader wraps an iterable around the Dataset to enable easy access to the samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XkAUW2Uo_uMI"
   },
   "source": [
    "### Creating Nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7HYZvPVbADSf"
   },
   "source": [
    "#### Ploting Client Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dhwTgIdsKyRW"
   },
   "outputs": [],
   "source": [
    "def plot_grid(data, samples = 25):\n",
    "    dim = int(samples/5)\n",
    "\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        \n",
    "        if(i == 3):\n",
    "            break\n",
    "\n",
    "        title = \"Client \" + str(i+1)\n",
    "        fig = plt.figure(figsize=(dim, dim))\n",
    "        plt.suptitle(title)\n",
    "        X, y =  next(iter(data[i]))\n",
    "            \n",
    "        for j in range(samples):\n",
    "            fig.add_subplot(dim, 5, j+1)\n",
    "            image = X[j][0]\n",
    "            plt.imshow(image, cmap='gray')\n",
    "            plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mkWE9c07Kp9u"
   },
   "source": [
    "#### Client's Datastuctures\n",
    "\n",
    "    Client - 3 (list)\n",
    "    - iid_train[0]\n",
    "    - iid_train[1]\n",
    "    - iid_train[2]\n",
    "\n",
    "    iter(iid_train[0]) gives an iterator to 8 batches(size 25)\n",
    "\n",
    "    iid_train[\n",
    "        client--> 0/2\n",
    "        [\n",
    "            batch --> 0/8\n",
    "            [\n",
    "                25 images tensor --> [], \n",
    "                25 labels tensor --> []\n",
    "            ],[[[], []],... , [[[], []]],\n",
    "        client--> 1/2\n",
    "        [[],[],[],[],[],[],[],[]], \n",
    "        client--> 2/2\n",
    "        [[],[],[],[],[],[],[],[]]\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.MNIST(\n",
    "        root = './data',\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform = torchvision.transforms.ToTensor()\n",
    "    )\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root = './data',\n",
    "    train = False,\n",
    "    download = True,\n",
    "    transform = torchvision.transforms.ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import threading\n",
    "import time\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "clients = []\n",
    "registration_open = True\n",
    "\n",
    "@app.route(\"/register\", methods=[\"POST\"])\n",
    "def register_client():\n",
    "    if registration_open:\n",
    "        client_ip = request.remote_addr\n",
    "        data = request.get_json()\n",
    "        client_port = data[\"port\"]\n",
    "\n",
    "        client_addr = (client_ip, client_port) \n",
    "\n",
    "        if client_addr not in clients:\n",
    "            clients.append(client_addr)\n",
    "    else:\n",
    "        return jsonify({\"message\": \"Registration closed!\"}), 403\n",
    "\n",
    "    return jsonify({\"message\": \"Client registered successfully!\", \"clients\": clients})\n",
    "\n",
    "@app.route(\"/get_clients\", methods=[\"GET\"])\n",
    "def get_clients():\n",
    "    return jsonify({\"clients\": clients})\n",
    "\n",
    "\n",
    "# @app.route(\"/get_data\", methods=[\"GET\"])\n",
    "# def get_data():\n",
    "#     client_ip = request.remote_addr\n",
    "#     if client_ip not in client_data_map:\n",
    "#         return jsonify({\"message\": \"Client is not registered or has no assigned data.\"}), 404\n",
    "    \n",
    "#     payload = client_data_map[client_ip]\n",
    "\n",
    "#     return jsonify(payload)\n",
    "\n",
    "def close_registration(registration_timeout):\n",
    "    global registration_open\n",
    "\n",
    "    time.sleep(registration_timeout)\n",
    "    registration_open = False\n",
    "    print(\"REGISTRATION CLOSED\")\n",
    "\n",
    "def run_flask():\n",
    "    app.run(host=\"0.0.0.0\", port=5000)\n",
    "\n",
    "registration_timeout = 30\n",
    "\n",
    "threading.Thread(target=close_registration, args=(registration_timeout,), daemon=True).start()\n",
    "threading.Thread(target=run_flask, daemon=True).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "response = requests.get(\"http://localhost:5000/get_clients\").json()\n",
    "print(response)\n",
    "\n",
    "#CLIENT_LIST HOLDS LIST OF CLIENT IP ADDRESSES\n",
    "client_list = response['clients']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "\n",
    "## ONLY USING 1% OF DATASET\n",
    "total_train_size = len(train_dataset) // 100 + 2\n",
    "total_test_size = len(test_dataset) // 100\n",
    "\n",
    "# train_dataset only hold subset of full train dataset\n",
    "subset_indices = list(range(0, total_train_size))\n",
    "train_dataset = Subset(train_dataset, subset_indices)\n",
    "\n",
    "# test_dataset only hold subset of full test dataset\n",
    "subset_indices = list(range(0, total_test_size))\n",
    "test_dataset = Subset(test_dataset, subset_indices)\n",
    "\n",
    "classes = 10\n",
    "input_dim = 784\n",
    "\n",
    "num_train_samples = 5000\n",
    "num_test_samples = 1000\n",
    "shuffle = True\n",
    "\n",
    "num_clients = len(client_list)\n",
    "rounds = 30\n",
    "# batch_size = 128\n",
    "batch_size = 64\n",
    "epochs_per_client = 3\n",
    "learning_rate = 2e-2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.MNIST(\n",
    "        root = './data',\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform = torchvision.transforms.ToTensor()\n",
    "    )\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root = './data',\n",
    "    train = False,\n",
    "    download = True,\n",
    "    transform = torchvision.transforms.ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RzDAN7_PAFjT"
   },
   "source": [
    "#### IID Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N3VRfz2Gqpki"
   },
   "outputs": [],
   "source": [
    "client_data_map = {}\n",
    "# NETWORK LOGIC\n",
    "def push_data():\n",
    "    print(f\"Client Map: {len(client_data_map)}\")\n",
    "    for client_addr, payload in client_data_map.items():\n",
    "        client_ip, client_port = client_addr\n",
    "        train_payload, test_payload = payload\n",
    "\n",
    "        print(f\"PAYLOAD: {train_payload.keys()}\")\n",
    "        print(f\"PAYLOAD: {test_payload.keys()}\")\n",
    "        try:\n",
    "            for i in range(2):\n",
    "                url = f\"http://{client_ip}:{client_port}/send_data\"\n",
    "                response = requests.post(url, json=payload[i], timeout=5)\n",
    "\n",
    "                if response.status_code == 200:\n",
    "                    print(f\"Data successfully transferred to client {(client_ip, client_port)}\")\n",
    "                else:\n",
    "                    print(f\"Failed to send data to client {(client_ip, client_port)}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error sending data to {(client_ip, client_port)}: {e}\")\n",
    "\n",
    "def iid_uniform(dataset, num_clients, total_train_size, batch_size, is_train_data, shuffle=True):\n",
    "    print(f\"Number of clients: {num_clients}\")\n",
    "    samples_per_client = int(total_train_size / num_clients)\n",
    "    print(f\"Total train size: {total_train_size}\")\n",
    "    print(f\"Number of Samples: {samples_per_client}\")\n",
    "\n",
    "    # wrap an iterable around the dataset\n",
    "    loader = DataLoader(dataset, batch_size=samples_per_client, shuffle=shuffle)    # batch per client\n",
    "\n",
    "    itr = iter(loader)\n",
    "    data = []\n",
    "\n",
    "\n",
    "    for i in range(num_clients):\n",
    "        # takes next batch, unpacks it to (features, label), and makes into mini dataset via TensorDataset. \n",
    "        # PRODUCES DATALOADER FOR A CLIENT\n",
    "\n",
    "\n",
    "        # SEND DATA TO RESPECTIVE CLIENTS!\n",
    "        batch = next(itr)\n",
    "        features, labels = batch\n",
    "\n",
    "        node_dataloader = DataLoader(TensorDataset(*batch), batch_size=batch_size, shuffle=shuffle)    # each client is further broken down to more batches\n",
    "        \n",
    "        payload = {\"features\" : features.tolist(), \"labels\": labels.tolist()}\n",
    "        \n",
    "        client_ip = client_list[i]\n",
    "\n",
    "        if client_ip not in client_data_map:\n",
    "            client_data_map[client_ip] = [None, None]\n",
    "\n",
    "        if is_train_data:\n",
    "            payload['is_train_data'] = True\n",
    "            client_data_map[client_ip][0] = payload\n",
    "        else:\n",
    "            payload['is_train_data'] = False\n",
    "            client_data_map[client_ip][1] = payload\n",
    "\n",
    "        data.append(node_dataloader)\n",
    "\n",
    "    # returns list of iterable forms of client datasets\n",
    "    return data            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_iid_distribution(data_loaders):\n",
    "    # 1. Bar plot of samples per client\n",
    "    samples_per_client = [len(loader.dataset) for loader in data_loaders]\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Label Distribution\n",
    "    plt.subplot(1, 2, 2)\n",
    "    \n",
    "    labelMap = {j : [0 for i in range(num_clients)] for j in range(10)}     # tracks labels with the number of that label per client\n",
    "    \n",
    "    for i in range(len(data_loaders)):\n",
    "        loader = data_loaders[i]\n",
    "        for _, y in loader.dataset:\n",
    "            label = y.item()\n",
    "            labelMap[label][i] += 1\n",
    "    \n",
    "    x = range(num_clients)\n",
    "    bottom = np.zeros(num_clients)\n",
    "\n",
    "    colors = plt.cm.get_cmap('tab10')(np.linspace(0, 1, 10))\n",
    "\n",
    "    for label in range(10):\n",
    "        plt.bar(x, labelMap[label], bottom=bottom, label=f'Label {label}', \n",
    "                color=colors[label])\n",
    "        bottom += np.array(labelMap[label])\n",
    "    \n",
    "    plt.title('Label Distribution Across Clients')\n",
    "    plt.xlabel('Client ID')\n",
    "    plt.ylabel('Number of Samples')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Usage example:\n",
    "\n",
    "# distributed_data = iid_uniform(train_dataset, num_clients, num_train_samples, batch_size, True)\n",
    "\n",
    "# plot_iid_distribution(distributed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "69DbthPiAMGB"
   },
   "source": [
    "#### Non-IID Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m0k1LtYYRVFk"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def non_iid_uniform(dataset, numClients, total_train_size, batch_size, is_train_data, shuffle):\n",
    "    samples_per_client = total_train_size // numClients\n",
    "    \n",
    "    print(\"Creating Non-IID Uniform Split...\")\n",
    "    \n",
    "    ## HARDCODED FOR MNIST!!!\n",
    "    num_of_labels = 10\n",
    "\n",
    "    client_labels = list()  # each element will hold random 30% of labels\n",
    "    labels_per_client = (int) (num_of_labels * 0.3)\n",
    "\n",
    "    for i in range(numClients):\n",
    "        client_labels.append(random.sample(range(0, 9), labels_per_client)) # randomly selects 30% of dataset\n",
    "\n",
    "\n",
    "    loader = DataLoader(dataset, batch_size=(numClients * samples_per_client), shuffle=shuffle) # 1 batch of the whole dataset\n",
    "    itr = iter(loader)\n",
    "    images, labels = next(itr)  # images, labels hold the whole dataset\n",
    "\n",
    "\n",
    "    data = []\n",
    "\n",
    "    maxSize = samples_per_client\n",
    "\n",
    "    image_list, label_list = [], []\n",
    "\n",
    "    for i in range(numClients):\n",
    "        is_label_equal = []\n",
    "\n",
    "        # Check every label in client_labels[i]\n",
    "        \n",
    "        for client_label in client_labels[i]:\n",
    "            is_label_equal.append(client_label == labels)\n",
    "\n",
    "        index = torch.stack(is_label_equal) # torch.stack combines is_label_equal tensors into 1 tensor\n",
    "        index = index.sum(0)    # any column that doesn't have 1 will be False, otherwise True\n",
    "        index = index.bool()    # Converts 0s and 1s back to True/False\n",
    "\n",
    "        new_images, new_labels = images[index], labels[index]\n",
    "\n",
    "        ## INDEX ACTS AS A BOOLEAN MASK\n",
    "        image_list.append(new_images)\n",
    "        label_list.append(new_labels)\n",
    "\n",
    "        maxSize = min(maxSize, len(new_images))\n",
    "\n",
    "\n",
    "    for i in range(len(image_list)):\n",
    "        new_images, new_labels = image_list[i], label_list[i]\n",
    "\n",
    "        features, labels = new_images[:maxSize], new_labels[:maxSize]\n",
    "        payload = {\"features\": features.tolist(), \"labels\": labels.tolist()}\n",
    "\n",
    "        client_ip = client_list[i]\n",
    "\n",
    "        if client_ip not in client_data_map:\n",
    "            client_data_map[client_ip] = [None, None]\n",
    "        if is_train_data:\n",
    "            payload['is_train_data'] = True\n",
    "            client_data_map[client_ip][0] = payload\n",
    "        else:\n",
    "            payload['is_train_data'] = False\n",
    "            client_data_map[client_ip][1] = payload\n",
    "\n",
    "        node_dataloader_ = DataLoader(TensorDataset(features, labels), batch_size=batch_size, shuffle=shuffle)\n",
    "        data.append(node_dataloader_)\n",
    "\n",
    "    return data\n",
    "\n",
    "# non_iid_uniform(train_dataset, num_clients, num_train_samples, batch_size, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_non_iid_distribution(data_loaders):\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    \n",
    "    # Create label map for each client\n",
    "    labelMap = {j: [0 for i in range(len(data_loaders))] for j in range(10)}\n",
    "    \n",
    "    # Count labels per client\n",
    "    for i in range(len(data_loaders)):\n",
    "        loader = data_loaders[i]\n",
    "        for _, y in loader.dataset:\n",
    "            label = y.item()\n",
    "            labelMap[label][i] += 1\n",
    "    \n",
    "    # Create stacked bar chart\n",
    "    x = range(len(data_loaders))\n",
    "    bottom = np.zeros(len(data_loaders))\n",
    "    \n",
    "    # Use distinct colors for each label\n",
    "    colors = plt.cm.get_cmap('tab10')(np.linspace(0, 1, 10))\n",
    "    \n",
    "    for label in range(10):\n",
    "        plt.bar(x, labelMap[label], bottom=bottom, \n",
    "                label=f'Label {label}', \n",
    "                color=colors[label])\n",
    "        bottom += np.array(labelMap[label])\n",
    "    \n",
    "    plt.title('Label Distribution Across Clients (Non-IID)')\n",
    "    plt.xlabel('Client ID')\n",
    "    plt.ylabel('Number of Samples')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Usage:\n",
    "# train_non_iid_data = non_iid_uniform(train_dataset, num_clients, num_train_samples, batch_size, True)\n",
    "# plot_non_iid_distribution(train_non_iid_data)\n",
    "\n",
    "# test_non_iid_data = non_iid_uniform(test_dataset, num_clients, num_train_samples, batch_size, True)\n",
    "# plot_non_iid_distribution(test_non_iid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_iid_skewed(dataset, numClients, total_train_size, batch_size, is_train_data, shuffle):\n",
    "    print(\"Creating Non-IID Skewed Split...\")\n",
    "    \n",
    "    ## HARDCODED FOR MNIST!!!\n",
    "    num_of_labels = 10\n",
    "\n",
    "    client_labels = list()  # each element will hold random 30% of labels\n",
    "    labels_per_client = (int) (num_of_labels * 0.3)\n",
    "\n",
    "    for i in range(numClients):\n",
    "        client_labels.append(random.sample(range(0, 9), labels_per_client)) # randomly selects 30% of dataset\n",
    "\n",
    "\n",
    "    loader = DataLoader(dataset, batch_size=(total_train_size), shuffle=shuffle) # 1 batch of the whole dataset\n",
    "    itr = iter(loader)\n",
    "    images, labels = next(itr)  # images, labels hold the whole dataset\n",
    "\n",
    "\n",
    "    data = []\n",
    "    \n",
    "    image_list, label_list = [], []\n",
    "\n",
    "    for i in range(numClients):\n",
    "        is_label_equal = []\n",
    "\n",
    "        # Check every label in client_labels[i]\n",
    "        \n",
    "        for client_label in client_labels[i]:\n",
    "            is_label_equal.append(client_label == labels)\n",
    "\n",
    "        index = torch.stack(is_label_equal) # torch.stack combines is_label_equal tensors into 1 tensor\n",
    "        index = index.sum(0)    # any column that doesn't have 1 will be False, otherwise True\n",
    "        index = index.bool()    # Converts 0s and 1s back to True/False\n",
    "\n",
    "        new_images, new_labels = images[index], labels[index]\n",
    "\n",
    "        ## INDEX ACTS AS A BOOLEAN MASK\n",
    "        image_list.append(new_images)\n",
    "        label_list.append(new_labels)\n",
    "\n",
    "\n",
    "    proportionsPerClient = [0.5, 0.25, 0.15, 0.10]\n",
    "    for i in range(len(image_list)):\n",
    "        new_images, new_labels = image_list[i], label_list[i]\n",
    "\n",
    "        clientSize = int(total_train_size * proportionsPerClient[i])\n",
    "\n",
    "        features, labels = new_images[:clientSize], new_labels[:clientSize]\n",
    "\n",
    "        payload = {\"features\": features.tolist(), \"labels\": labels.tolist()}\n",
    "        client_ip = client_list[i]\n",
    "\n",
    "        if client_ip not in client_data_map:\n",
    "            client_data_map[client_ip] = [None, None]\n",
    "        if is_train_data:\n",
    "            payload['is_train_data'] = True\n",
    "            client_data_map[client_ip][0] = payload\n",
    "        else:\n",
    "            payload['is_train_data'] = False\n",
    "            client_data_map[client_ip][1] = payload\n",
    "\n",
    "        node_dataloader_ = DataLoader(TensorDataset(features, labels), batch_size=batch_size, shuffle=shuffle)\n",
    "        data.append(node_dataloader_)\n",
    "\n",
    "    push_data()\n",
    "\n",
    "    return data\n",
    "\n",
    "# train_non_iid_skewed = non_iid_skewed(train_dataset, num_clients, num_train_samples, batch_size, True)\n",
    "# plot_non_iid_distribution(train_non_iid_skewed)\n",
    "\n",
    "# test_non_iid_skewed = non_iid_skewed(test_dataset, num_clients, num_train_samples, batch_size, True)\n",
    "# plot_non_iid_distribution(test_non_iid_skewed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ABaaH0D8AT0I"
   },
   "source": [
    "#### Loading MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "biet1v-Ywmpw"
   },
   "source": [
    "##### **About MNIST Dataset**\n",
    "\n",
    "MNIST Handwritten Digit Classification Dataset\n",
    "The MNIST dataset is an acronym that stands for the Modified National Institute of Standards and Technology dataset.\n",
    "\n",
    "It is a dataset of 60,000 small square 28×28 pixel grayscale images of handwritten single digits between 0 and 9. The task is to classify a given image of a handwritten digit into one of 10 classes representing integer values from 0 to 9, inclusively.\n",
    "\n",
    "It is a widely used and deeply understood dataset and, for the most part, is “solved.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GWz1wdQRoADI"
   },
   "outputs": [],
   "source": [
    "def get_MNIST(type='iid', n_samples_train = 200, n_samples_test= 100, n_clients=3, batch_size=25, shuffle=True):\n",
    "\n",
    "    # Download MNIST train and test dataset\n",
    "\n",
    "    train_dataset = torchvision.datasets.MNIST(\n",
    "        root = './data',\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform = torchvision.transforms.ToTensor()\n",
    "    )\n",
    "    print(len(train_dataset))\n",
    "\n",
    "    test_dataset = torchvision.datasets.MNIST(\n",
    "        root = './data',\n",
    "        train = False,\n",
    "        download = True,\n",
    "        transform = torchvision.transforms.ToTensor()\n",
    "    )\n",
    "\n",
    "    print(\"Classes: \", train_dataset.classes)\n",
    "    print(\"Number of classes: \", len(train_dataset.classes))\n",
    "    \n",
    "\n",
    "    if type == \"iid\":\n",
    "        print(\"Train Dataset\")\n",
    "        train = iid_uniform(train_dataset, n_clients, n_samples_train, batch_size, True, shuffle)\n",
    "        plot_iid_distribution(train)\n",
    "        print(\"Test Dataset\")\n",
    "        test = []\n",
    "        test =  iid_uniform(test_dataset, n_clients, n_samples_test, batch_size, False, shuffle)\n",
    "        plot_iid_distribution(test)\n",
    "        push_data()\n",
    "\n",
    "    elif type == \"non_iid\":\n",
    "        print(\"Train Dataset\")\n",
    "        train = non_iid_uniform(train_dataset, n_clients, n_samples_train, batch_size, True, shuffle)\n",
    "        plot_non_iid_distribution(train)\n",
    "        print(\"Test Dataset\")\n",
    "        test =  non_iid_uniform(test_dataset, n_clients, n_samples_test, batch_size, False, shuffle)\n",
    "        plot_non_iid_distribution(test)\n",
    "        push_data()\n",
    "\n",
    "    elif type == \"non_iid_skewed\":\n",
    "        print(\"Train Dataset\")\n",
    "        train = non_iid_skewed(train_dataset, n_clients, n_samples_train, batch_size, True, shuffle)\n",
    "        plot_non_iid_distribution(train)\n",
    "        print(\"Test Dataset\")\n",
    "        test =  non_iid_skewed(test_dataset, n_clients, n_samples_test, batch_size, False, shuffle)\n",
    "        plot_non_iid_distribution(test)\n",
    "        push_data()\n",
    "\n",
    "    else:\n",
    "        train = []\n",
    "        test = []\n",
    "\n",
    "    # return train, test (AS LIST OF DATALOADERS)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pfm2JqesCLQq"
   },
   "source": [
    "#### Loading Synthetic MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aLjmU4EcCQog"
   },
   "outputs": [],
   "source": [
    "!cp  /content/drive/MyDrive/ML/syntheticMNIST.py /content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qOjb23LlImBV"
   },
   "outputs": [],
   "source": [
    "!pip install scipy\n",
    "import syntheticMNIST as syn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jfUTxjmHMhUA"
   },
   "outputs": [],
   "source": [
    "# def synthetic_client_config(type=\"non_iid\", num_clients=3, train_samples=90, test_samples=30):\n",
    "#     C= {\n",
    "#      'n_samples_train': train_samples,\n",
    "#      'font':'DejaVu Sans',\n",
    "#      'tilt': [0, 45, 90],\n",
    "#      'std_tilt': 10, #std on the tilt,\n",
    "#      'seed':0\n",
    "#      }\n",
    "\n",
    "#     C['n_samples']= train_samples + test_samples\n",
    "#     clients = []\n",
    "#     if(type==\"non_iid\"):\n",
    "#         for i in range(num_clients):\n",
    "\n",
    "#             new_C =deepcopy(C)\n",
    "#             num_labels = random.randint(2, 5)\n",
    "#             new_C['numbers'] = random.sample(range(0, 9), num_labels)\n",
    "#             clients.append(new_C)\n",
    "#     if(type==\"iid\"):\n",
    "#         for i in range(num_clients):\n",
    "\n",
    "#             new_C =deepcopy(C)\n",
    "#             new_C['numbers'] = random.sample(range(0, 10), 9)\n",
    "#             clients.append(new_C)\n",
    "\n",
    "#     return clients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xbE1QBRKQ92C"
   },
   "source": [
    "#### Generating Clients and Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3OkRiK8eQ9YB"
   },
   "outputs": [],
   "source": [
    "num_train_samples = 500\n",
    "num_test_samples = 100\n",
    "batch_size = 25\n",
    "shuffle = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6OZe_G4EROGB"
   },
   "source": [
    "IID Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 616,
     "referenced_widgets": [
      "4c58dae243554c46a25f4be58bf887a1",
      "741762232f394a5bb08d394234dd016c",
      "5ce35183b9f34799a93be7e9c88edf47",
      "c5c4f8289da844f7b58ccb698709f70e",
      "e979eb222e724a8f914aea3b8273efa4",
      "431b924395cd480ca4b910d239547871",
      "6902054c7f634fa096f6c7fec81957c6",
      "3543fbdbb9d04ae2b0a99eccc105db66",
      "c65d30fb86954a5e8e6fbdf2e687fdd5",
      "1dc418b8b3e74b74b8ea5dc02a48b12d",
      "cb280b2482d9468682aa2281321a7586",
      "a4d3281bf34144ffb732dac0f253e3f0",
      "acc1455bae7f4fd2bf5f61fb1b75f867",
      "5cb54245865a4756bf36ff974c9d58b3",
      "16406388f92541d883a302f2f13b9fcf",
      "b24725b3b4c141b38eebe6bca56439b6",
      "23949ae951e1485f9fa3adfa7e66c160",
      "fa07f9ea000b4e55ba29834ede2b71d6",
      "2996075ff05849d9b35e2f1aeeab782a",
      "70d0223b99974b5a835426ae83290680",
      "d9dce3b52fe6441b874302ce4a530274",
      "5cb3135ab32a44e0989626956d8bfbd0",
      "4ce5a57d913b4cee9f023eabaebe3c91",
      "558a63cdf465494ebc0f02cd530daf19",
      "f07cdd1bb93440a0a75f0cb8fe1f7a0d",
      "2fa22b25f2554cd98648371a1ee36f19",
      "650eb647f75f4818b65d2a5a2560e63d",
      "6ba5b9b3f5404af8ba23059e920907dd",
      "eba170fbd76c4b09af8b6ef333c10ba7",
      "7d2638141f844805982a037cfe00d065",
      "d07c6cc1d5c8498785b65b33b4693656",
      "d86de62e5740453284247fac415fa9c3",
      "b552821412d740cca4e7cb93735fcb5c",
      "6da43a5f9bd148c9844623fb118e2a41",
      "181e3aa4062346a7a99ea80a0c01e320",
      "c6d8e41521be44239755e556f68661f3",
      "8d277fee9e60474aafeaea502a0fd102",
      "37c752ef30e7422ab7c81e08a561af47",
      "0d4e8c5f50b84c349d85c034fcccf499",
      "2d363ca81d1447828a5af952a0a0d816",
      "c68ceec27cc94e2f9ad531eb9dca7261",
      "0d50bd19bfc14bf2b9f57c1014a8f7b5",
      "556274a6447d43a998a0f76bbfe7f7ca",
      "47e8d63034cd45308a065d138468dac7"
     ]
    },
    "id": "NnpmbpD0RQeO",
    "outputId": "faa91b68-db8f-4b51-b84b-1086fea84fc6"
   },
   "outputs": [],
   "source": [
    "iid_train, iid_test = get_MNIST(type='iid', n_samples_train = num_train_samples, \n",
    "                                n_samples_test= num_test_samples, n_clients=num_clients,\n",
    "                                batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "iid_client = [iid_train, iid_test]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wvt6Wei-RoWM"
   },
   "source": [
    "Non-IID Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7VXiG9XJRWts",
    "outputId": "2dac454a-b7a9-462e-e7ca-3852c5e0ec1d"
   },
   "outputs": [],
   "source": [
    "niid_train, niid_test = get_MNIST(type=\"non_iid\", n_samples_train = num_train_samples,\n",
    "                                  n_samples_test= num_test_samples, n_clients=num_clients,\n",
    "                                  batch_size=batch_size, shuffle=shuffle)\n",
    "niid_client = [niid_train, niid_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YemRCyulRr1O"
   },
   "source": [
    "Synthetic Non-IID Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pP448MzzRqzo",
    "outputId": "0ba9b134-885f-4bb0-fd9b-bd1945e89fcb"
   },
   "outputs": [],
   "source": [
    "# clients_config = synthetic_client_config(type=\"iid\", num_clients=num_clients, \n",
    "#                                          train_samples=num_train_samples, \n",
    "#                                          test_samples=num_test_samples)\n",
    "\n",
    "# iid_train_syn, iid_test_syn = syn.get_synth_MNIST(clients_config, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "# iid_syn_client = [iid_train_syn, iid_test_syn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MPNZSGlASrfF",
    "outputId": "7953d6d3-56e3-4a21-a376-566e665a17ee"
   },
   "outputs": [],
   "source": [
    "# clients_config = synthetic_client_config(type=\"non_iid\", num_clients=num_clients, \n",
    "#                                          train_samples=num_train_samples, \n",
    "#                                          test_samples=num_test_samples)\n",
    "\n",
    "# niid_train_syn, niid_test_syn = syn.get_synth_MNIST(clients_config, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "# niid_syn_client = [niid_train_syn, niid_test_syn]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9lu7pyXO-_k8"
   },
   "source": [
    "#### Plotting Generated Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 859
    },
    "id": "imqyMYyTbruf",
    "outputId": "de04cb66-cf93-4348-b5ec-aaf23fcbceaf"
   },
   "outputs": [],
   "source": [
    "# print(\"IID Synthetic Training Dataset\")\n",
    "# iid_train_syn[0].dataset.plot_samples(0, \"Client 1\")\n",
    "# iid_train_syn[1].dataset.plot_samples(0, \"Client 2\")\n",
    "# iid_train_syn[2].dataset.plot_samples(0, \"Client 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 859
    },
    "id": "wHusxMWUUllW",
    "outputId": "122135a6-c568-4d24-eaed-9da2c3561ef5"
   },
   "outputs": [],
   "source": [
    "# print(\"Non-IID Synthetic Training Dataset\")\n",
    "# niid_train_syn[0].dataset.plot_samples(0, \"Client 1\")\n",
    "# niid_train_syn[1].dataset.plot_samples(0, \"Client 2\")\n",
    "# niid_train_syn[2].dataset.plot_samples(0, \"Client 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "It1rpUfmFVee"
   },
   "source": [
    "### Models and functions for federated learning algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k4oac9GOWG9m"
   },
   "source": [
    "Features and Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W9TKpcFSHAdd"
   },
   "outputs": [],
   "source": [
    "num_features = 28*28\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TMscBWsCWLkS"
   },
   "source": [
    "Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5siDQhk_FbgC"
   },
   "outputs": [],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(num_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1, 28*28)\n",
    "        output = self.linear(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IF4lxSceTddW"
   },
   "outputs": [],
   "source": [
    "model_0 = LogisticRegression()\n",
    "model_1 = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nSQQglDHIWsI"
   },
   "source": [
    "**Averaging Models Example**\n",
    "\n",
    "We can get the `state_dicts` of both models, average the parameters and reload the new `state_dict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JzGYa50vDGz9",
    "outputId": "125bdff8-5256-4623-c0bc-f4d4bd588731"
   },
   "outputs": [],
   "source": [
    "# Setup\n",
    "sdA = model_0.state_dict()\n",
    "sdB = model_1.state_dict()\n",
    "sdC = {}\n",
    "\n",
    "# Average all parameters\n",
    "for key in sdA:\n",
    "    sdC[key] = (sdB[key] + sdA[key])/2\n",
    "\n",
    "# Recreate model and load averaged state_dict (or use modelA/B)\n",
    "model_2 = LogisticRegression()\n",
    "model_2.load_state_dict(sdC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gqhYxALdTmbM"
   },
   "source": [
    "#### Functions for Federated Algos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z-rwEG6BeogL"
   },
   "outputs": [],
   "source": [
    "class History:\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.loss = []       # stores model loss\n",
    "        self.accuracy = []   # stores model accuracy\n",
    "        self.model = []      # stores model\n",
    "        self.variance = []\n",
    "\n",
    "    def log_server(self, model, client, loss_func):\n",
    "        # Logging loss to history\n",
    "        curr_loss = [(float)(get_dataset_loss(model, dataset, loss_func).detach()) for dataset in client[0]]\n",
    "        # self.client_loss.append(curr_loss)\n",
    "        self.loss.append(sum(curr_loss)/len(curr_loss))\n",
    "\n",
    "        # Logging accuracy to history\n",
    "        curr_acc = [get_dataset_accuracy(model, dataset) for dataset in client[1]]\n",
    "        # self.client_acc.append(curr_acc)\n",
    "\n",
    "        client_acc_avg = sum(curr_acc)/len(curr_acc)\n",
    "        self.accuracy.append(client_acc_avg)\n",
    "\n",
    "        # Logging model to history\n",
    "        self.model.append(model.state_dict())\n",
    "\n",
    "\n",
    "        # Logging variance\n",
    "        sumVar = 0\n",
    "        for i in range(len(client[1])):\n",
    "            sumVar += ((curr_acc[i] - client_acc_avg) ** 2)\n",
    "\n",
    "        if len(client[1]) == 1:\n",
    "            self.variance.append(0)\n",
    "        else:\n",
    "            self.variance.append(sumVar / (len(client[1]) - 1))\n",
    "\n",
    "    def log_client(self, model, dataset, loss):\n",
    "        # Logging loss to history\n",
    "        self.loss.append(loss)\n",
    "\n",
    "        # Logging accuracy to history\n",
    "        curr_acc = get_dataset_accuracy(model, dataset)\n",
    "        self.accuracy.append(curr_acc)\n",
    "\n",
    "        # Logging model to history\n",
    "        self.model.append(model.state_dict())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8YYQfSmgl8DD"
   },
   "outputs": [],
   "source": [
    "def loss_classifier(predictions, labels):\n",
    "\n",
    "    loss = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "    return loss(predictions, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GYLQZOZhyFhg"
   },
   "outputs": [],
   "source": [
    "def get_accuracy(predictions, labels):\n",
    "\n",
    "     _, predicted = torch.max(predictions, dim=1)\n",
    "     accuracy = torch.sum(predicted == labels).item()/len(predicted)\n",
    "     return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "baMtf2kqh9_h"
   },
   "outputs": [],
   "source": [
    "def get_dataset_loss(model, dataset, loss_func):\n",
    "    # Compute loss of a model on given dataset\n",
    "\n",
    "    total_loss = 0\n",
    "    for batch in dataset:\n",
    "        features, labels = batch\n",
    "        predictions = model(features)\n",
    "        total_loss += loss_func(predictions, labels)\n",
    "\n",
    "    avg_loss = total_loss/len(dataset)\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yp-a4Ncwu87z"
   },
   "outputs": [],
   "source": [
    "def get_dataset_accuracy(model, dataset):\n",
    "\n",
    "    total_accuracy = 0\n",
    "    for batch in dataset:\n",
    "        features, labels = batch\n",
    "        predictions = model(features)\n",
    "        curr_accuracy = get_accuracy(predictions, labels)\n",
    "        total_accuracy += curr_accuracy\n",
    "    \n",
    "    avg_accuracy = (total_accuracy/len(dataset))*100\n",
    "    return avg_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lI-6aN5HrkBx"
   },
   "outputs": [],
   "source": [
    "def train(model, batch, loss_func):\n",
    "    images, labels = batch\n",
    "    preds = model(images)\n",
    "    loss = loss_func(preds, labels)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lNSqoIwdt_Tx"
   },
   "outputs": [],
   "source": [
    "def diff_squared_sum(model1, model2):\n",
    "    w1 = model1.linear.weight\n",
    "    w2 = model2.linear.weight\n",
    "    w = (w1-w2).pow(2).sum()\n",
    "\n",
    "    b1 = model1.linear.bias\n",
    "    b2 = model2.linear.bias\n",
    "    b = (b1-b2).pow(2).sum()\n",
    "    \n",
    "    dss = w + b\n",
    "   \n",
    "\n",
    "    return dss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RedfmkgUf-xn"
   },
   "outputs": [],
   "source": [
    "def get_model_avg(history):\n",
    "\n",
    "    # Setup\n",
    "    model_state = history.model\n",
    "    sd = {k: torch.zeros_like(v) for k, v in model_state[0].items()} # create state dictionary\n",
    "\n",
    "    # Zero all the values of state dictionary\n",
    "    for key in sd:\n",
    "        sd[key] = 0\n",
    "\n",
    "    # Average all parameters\n",
    "    n = len(model_state)\n",
    "    for state in model_state:\n",
    "        for key in sd:\n",
    "            sd[key] += state[key]*(1/n)\n",
    "    \n",
    "    # Recreate model and load averaged state_dict (or use modelA/B)\n",
    "    model = LogisticRegression()\n",
    "    model.load_state_dict(sd)\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGbqCkcI9vnd"
   },
   "source": [
    "#### Federated Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SAyYhGFIPiqp"
   },
   "source": [
    "##### FedAvg and FedProx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ybV7m-qDWnlg"
   },
   "outputs": [],
   "source": [
    "def serialize_model(model):\n",
    "    state_dict = model.state_dict()\n",
    "    serialized = {key: value.tolist() for key, value in state_dict.items()}\n",
    "    return serialized\n",
    "\n",
    "\n",
    "\n",
    "def Fed(server_model, clients, client_fraction=1, rounds=10, epochs=10, learning_rate=0.01, decay=1, model_type=\"avg\", straggler_percent=0, mu=0, q=0):\n",
    "    model = deepcopy(server_model)\n",
    "    loss_func = loss_classifier\n",
    "    K = len(clients[0])        # number of clients (train dataset)\n",
    "\n",
    "    server_history = History()\n",
    "    server_history.log_server(model, clients, loss_func)\n",
    "\n",
    "    print(\"Starting...\")\n",
    "    print(\"Clients:\", K, \"| Learning Rate:\", learning_rate, \"| mu:\", mu, \"| Epochs:\", epochs)\n",
    "    print(\"Running for\", rounds, \"rounds |\")\n",
    "\n",
    "    for i in range(rounds):\n",
    "        # Calculate number of clients with given fraction\n",
    "        m = max(math.floor(K*client_fraction), 1)\n",
    "\n",
    "        # Select random set on m clients\n",
    "        # represents key in client name : client ip\n",
    "        s = random.sample(range(0, K), m) # for now selecting all clients\n",
    "\n",
    "        local_history = History()\n",
    "        server_model = deepcopy(model)\n",
    "\n",
    "        for j in range(len(s)):\n",
    "            client_data = client_list[s[j]]\n",
    "            client_ip, client_port = client_data\n",
    "            \n",
    "            url = f\"http://{client_ip}:{client_port}/client_update\"\n",
    "            payload = {\n",
    "                \"model\": serialize_model(server_model),\n",
    "                \"learning_rate\": learning_rate,\n",
    "                \"epochs\": epochs,\n",
    "                \"mu\": mu,\n",
    "                \"type\": model_type\n",
    "            }\n",
    "            response = requests.post(url, json=payload)\n",
    "\n",
    "            client_data = response.json()\n",
    "\n",
    "            local_history.loss.append(client_data[\"loss\"])\n",
    "            local_history.accuracy.append(client_data[\"accuracy\"])\n",
    "\n",
    "            client_state_dict = {k: torch.tensor(v) for k, v in client_data['model'][0].items()}\n",
    "\n",
    "\n",
    "            local_history.model.append(client_state_dict)\n",
    "\n",
    "        model = get_model_avg(local_history)\n",
    "        server_history.log_server(model, clients, loss_func)\n",
    "        \n",
    "        # Decrease the learning rate with each rounds\n",
    "        # learning_rate = learning_rate*decay\n",
    "\n",
    "        if(i%(rounds/10) == 0):\n",
    "            print(\"\\b+++\")\n",
    "\n",
    "    hist = server_history\n",
    "    for i in range(len(hist.loss)):\n",
    "        if(i%(rounds/10) == 0):\n",
    "            print(\"Loss: {:.4f}, Accuracy: {:.4f}\".format(hist.loss[i], hist.accuracy[i]))\n",
    "\n",
    "    print(\"End\")\n",
    "    \n",
    "    return model, server_history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_0G2Vh4RP25A"
   },
   "source": [
    "##### qFedAvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dO3gVQQbU38e"
   },
   "outputs": [],
   "source": [
    "def normal(delta_ws):\n",
    "   \n",
    "    w = (delta_ws[0]).pow(2).sum()\n",
    "    b = (delta_ws[1]).pow(2).sum()\n",
    "\n",
    "    ss = w + b\n",
    "    return ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xCh0AzqkGLDr"
   },
   "outputs": [],
   "source": [
    "def q_aggregate(server_model, deltas, hs):\n",
    "    num_clients = len(deltas)\n",
    "\n",
    "    de = np.sum(np.asarray(hs))\n",
    "    \n",
    "    # Scale client deltas by multiplying (1/denominator)\n",
    "    scaled_deltas = []\n",
    "    for client_delta in deltas:\n",
    "        print(client_delta[0])\n",
    "        scaled_deltas.append([(layer * 1.0 / de) for layer in client_delta])\n",
    "\n",
    "    # Sum scaled client deltas\n",
    "    sum_delta = deltas[0]\n",
    "    for i in range(len(scaled_deltas)):\n",
    "        if(i > 0):\n",
    "            sum_delta = [(sd+d) for sd, d in zip(sum_delta, scaled_deltas[i])]\n",
    "\n",
    " \n",
    "    # Update server model\n",
    "    model = deepcopy(server_model)\n",
    "   \n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.linear.weight -= sum_delta[0]\n",
    "        model.linear.bias -=  sum_delta[1]\n",
    "\n",
    "\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RziboHntP7oZ"
   },
   "outputs": [],
   "source": [
    "def qFed(server_model, clients, client_fraction=1, rounds=10, epochs=10, learning_rate=0.01, q=0):\n",
    "    \n",
    "    model = deepcopy(server_model)\n",
    "    loss_func = loss_classifier\n",
    "    K = len(clients[0])        # number of clients\n",
    "\n",
    "    server_history = History()\n",
    "    server_history.log_server(model, clients, loss_func)\n",
    "\n",
    "    print(\"Starting...\")\n",
    "    print(\"Clients:\", K, \"| Learning Rate:\", learning_rate, \"| q:\", q, \"| Epochs:\", epochs)\n",
    "    print(\"Running for\", rounds, \"rounds |\")\n",
    "\n",
    "    for i in range(rounds):\n",
    "       \n",
    "        # Calculate number of clients with given fraction\n",
    "        m = max(math.floor(K*client_fraction), 1)\n",
    "\n",
    "        # Select random set on m clients\n",
    "        s = random.sample(range(0, K), m) # for now selecting all clients\n",
    "        \n",
    "        local_history = History()\n",
    "        s_model = deepcopy(model)\n",
    "\n",
    "\n",
    "        deltas = []\n",
    "        hs = []\n",
    "        for j in range(len(s)):\n",
    "            client_ip = client_list[s[j]]\n",
    "            url = f\"http://{client_ip}:6001/q_client_update\"\n",
    "            payload = {\n",
    "                \"model\": serialize_model(server_model),\n",
    "                \"learning_rate\": learning_rate,\n",
    "                \"epochs\": epochs,\n",
    "                \"q_val\": q\n",
    "            }\n",
    "            response = requests.post(url, json=payload)\n",
    "            client_data = response.json()\n",
    "\n",
    "            delta = [torch.tensor(layer) for layer in client_data['delta']]\n",
    "            h = torch.tensor(client_data['h'])\n",
    "            \n",
    "            local_history.loss.append(client_data[\"loss\"])\n",
    "            local_history.accuracy.append(client_data[\"accuracy\"])\n",
    "\n",
    "            client_state_dict = {k: torch.tensor(v) for k, v in client_data['model'][0].items()}\n",
    "            local_history.model.append(client_state_dict)\n",
    "\n",
    "            deltas.append(delta)\n",
    "            hs.append(h)\n",
    "\n",
    "        model = q_aggregate(s_model, deltas, hs)\n",
    "        server_history.log_server(model, clients, loss_func)\n",
    "    \n",
    "\n",
    "        if(i%(rounds/10) == 0):\n",
    "            print(\"\\b+++\")\n",
    "\n",
    "    hist = server_history\n",
    "    for i in range(len(hist.loss)):\n",
    "        print(\"Loss: {:.4f}, Accuracy: {:.4f}\".format(hist.loss[i], hist.accuracy[i]))\n",
    "\n",
    "    print(\"End\")\n",
    "    \n",
    "    return model, server_history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0foa0YzlAKIW"
   },
   "source": [
    "#### Plotting Loss and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2IzuLzGTQoHw"
   },
   "outputs": [],
   "source": [
    "def plot_loss(loss_list, name_list,  title):\n",
    "    df = pd.DataFrame(np.column_stack(loss_list), columns=name_list)\n",
    "    \n",
    "    fig = px.line(df, \n",
    "                x=list(range(0, len(loss_list[0]))),\n",
    "                y=df.columns[:], \n",
    "                labels={\n",
    "                    \"x\": \"Rounds\",\n",
    "                    \"value\": \"Loss\",\n",
    "                    # \"variable\": \"Clients\"\n",
    "                },\n",
    "                title=title\n",
    "            )\n",
    "\n",
    "    # Show plot \n",
    "    fig.show()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RojdFCtCQrB2"
   },
   "outputs": [],
   "source": [
    "\n",
    "def plot_acc(acc_list, name_list,  title):\n",
    "    df = pd.DataFrame(np.column_stack(acc_list), columns=name_list)\n",
    "    \n",
    "    fig = px.line(df, \n",
    "                x=list(range(0, len(acc_list[0]))),\n",
    "                y=df.columns[:], \n",
    "                labels={\n",
    "                    \"x\": \"Rounds\",\n",
    "                    \"value\": \"Accuracy\",\n",
    "                    # \"variable\": \"Clients\"\n",
    "                },\n",
    "                title=title\n",
    "            )\n",
    "\n",
    "    # Show plot \n",
    "    fig.show()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_variance(var_list, name_list, title):\n",
    "    df = pd.DataFrame(np.column_stack(var_list), columns=name_list)\n",
    "    \n",
    "    fig = px.line(df, \n",
    "                x=list(range(0, len(var_list[0]))),\n",
    "                y=df.columns[:], \n",
    "                labels={\n",
    "                    \"x\": \"Rounds\",\n",
    "                    \"value\": \"Variance\",\n",
    "                    # \"variable\": \"Clients\"\n",
    "                },\n",
    "                title=title\n",
    "            )\n",
    "\n",
    "    # Show plot \n",
    "    fig.show()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F7fzHtd4FZ98"
   },
   "source": [
    "### Evaluating Models and Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2s6MNnrPovD9"
   },
   "source": [
    "Pamameters\n",
    "*   server_model\n",
    "*   clients \n",
    "*   client_fraction =1\n",
    "*   rounds =10\n",
    "*   mu = 0\n",
    "*   epochs = 10\n",
    "*   learning_rate = 0.01\n",
    "*   decay = 1\n",
    "*   type =\"avg\" (\"prox\", \"q-ffl\", \"avg\")\n",
    "*   straggler_percent = 0 (0 to 1)\n",
    "*   q = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qApU1_PKnQpj"
   },
   "outputs": [],
   "source": [
    "model = model_0\n",
    "rounds = 40\n",
    "epochs = 25\n",
    "lr = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oiz9w3U0GuQL"
   },
   "source": [
    "### IID Uniform Testing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2zioiSxsmySu",
    "outputId": "4f1a33e6-e797-436b-e2c9-d50a71199be4"
   },
   "outputs": [],
   "source": [
    "favg_iid_model, favg_iid_hist = Fed(server_model=model, clients=iid_client,\n",
    "                                    rounds=rounds, epochs=epochs, learning_rate=lr, model_type=\"avg\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "favg_iid_hist.variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomized Search Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UUJvAxh-ysM5",
    "outputId": "730c1e8c-cbb9-4c97-b1de-20f2087f9b0a"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import uniform\n",
    "\n",
    "class QFedOptimizer:\n",
    "    def __init__(self, server_model, clients, client_fraction=1, rounds=10, epochs=10):\n",
    "        self.server_model = server_model\n",
    "        self.clients = clients\n",
    "        self.client_fraction = client_fraction\n",
    "        self.rounds = rounds\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def train_and_evaluate(self, learning_rate, q):\n",
    "        model, history = qFed(\n",
    "            server_model=self.server_model,\n",
    "            clients=self.clients,\n",
    "            client_fraction=self.client_fraction,\n",
    "            rounds=self.rounds,\n",
    "            epochs=self.epochs,\n",
    "            learning_rate=learning_rate,\n",
    "            q=q\n",
    "        )\n",
    "        # Return final loss and accuracy\n",
    "        return history.loss[-1], history.accuracy[-1], history.variance[-1]\n",
    "\n",
    "def optimize_qfed_parameters(server_model, clients):\n",
    "    optimizer = QFedOptimizer(server_model, clients)\n",
    "    \n",
    "    # Define parameter space\n",
    "    search_space = {\n",
    "        \"learning_rate\": uniform(0.001, 0.1),\n",
    "        \"q\": uniform(0, 10)\n",
    "    }\n",
    "    \n",
    "    # Track best parameters\n",
    "    best_loss = float('inf')\n",
    "    best_params = None\n",
    "    best_accuracy = 0\n",
    "    best_variance = float('inf')\n",
    "    \n",
    "    # Number of trials\n",
    "    n_trials = 40\n",
    "    \n",
    "    for _ in range(n_trials):\n",
    "        # Sample parameters\n",
    "        lr = search_space[\"learning_rate\"].rvs()\n",
    "        q = search_space[\"q\"].rvs()\n",
    "        \n",
    "        # Train and evaluate\n",
    "        loss, accuracy, variance = optimizer.train_and_evaluate(lr, q)\n",
    "        \n",
    "        # Update best parameters BASED ON LOSS\n",
    "        if loss < best_loss:\n",
    "            best_variance = variance\n",
    "            best_loss = loss\n",
    "            best_accuracy = accuracy\n",
    "            best_params = {'learning_rate': lr, 'q': q}\n",
    "            \n",
    "        print(f\"Trial params: lr={lr:.6f}, q={q:.2f}\")\n",
    "        print(f\"Loss: {loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    return best_params\n",
    "\n",
    "best_params = optimize_qfed_parameters(server_model=model, clients=iid_client)\n",
    "\n",
    "best_lr, best_q = best_params.values()\n",
    "print(best_lr, best_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qffl_iid_model_q, qffl_iid_hist_q = qFed(server_model=model, clients=iid_client,\n",
    "                                    rounds=rounds, epochs=20, learning_rate=0.1, q=4)\n",
    "\n",
    "losses = [favg_iid_hist.loss, qffl_iid_hist_q.loss]\n",
    "line_names = [\"FedAvg\", \"qFedAvg(q>0)\"]\n",
    "title = \"Comparing different Fed Algorithms on IID Dataset\"\n",
    "df1 = plot_loss(losses, line_names, title)\n",
    "\n",
    "acc = [favg_iid_hist.accuracy, qffl_iid_hist_q.accuracy]\n",
    "line_names = [\"FedAvg\", \"q-FedAvg(q>0)\"]\n",
    "title = \"Comparing different Fed Algorithms on IID Dataset\"\n",
    "df2 = plot_acc(acc, line_names, title)\n",
    "\n",
    "variance = [favg_iid_hist.variance, qffl_iid_hist_q.variance]\n",
    "line_names = [\"FedAvg\", \"q-FedAvg(q>0)\"]\n",
    "title = \"Comparing different Fed Algorithms on IID Dataset\"\n",
    "df2 = plot_variance(variance, line_names, title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = optimize_qfed_parameters(server_model=model, clients=niid_client)\n",
    "\n",
    "best_lr, best_q = best_params.values()\n",
    "print(best_lr, best_q)\n",
    "\n",
    "qffl_niid_model_q0, qffl_niid_hist_q0 = qFed(server_model=model, clients=niid_client,\n",
    "                                    rounds=rounds, epochs=20, learning_rate=best_lr ,q=best_q)\n",
    "\n",
    "favg_niid_model, favg_niid_hist = Fed(server_model=model, clients=niid_client,\n",
    "                                    rounds=rounds, epochs=epochs, learning_rate=lr, model_type=\"avg\")\n",
    "\n",
    "losses = [favg_niid_hist.loss, qffl_niid_hist_q0.loss]\n",
    "line_names = [\"FedAvg\", \"qFedAvg(q>0)\"]\n",
    "title = \"Comparing different Fed Algorithms on IID Dataset\"\n",
    "df1 = plot_loss(losses, line_names, title)\n",
    "\n",
    "acc = [favg_niid_hist.accuracy, qffl_niid_hist_q0.accuracy]\n",
    "line_names = [\"FedAvg\", \"q-FedAvg(q>0)\"]\n",
    "title = \"Comparing different Fed Algorithms on IID Dataset\"\n",
    "df2 = plot_acc(acc, line_names, title)\n",
    "\n",
    "variance = [favg_niid_hist.variance, qffl_niid_hist_q0.variance]\n",
    "line_names = [\"FedAvg\", \"q-FedAvg(q>0)\"]\n",
    "title = \"Comparing different Fed Algorithms on IID Dataset\"\n",
    "df2 = plot_variance(variance, line_names, title)\n",
    "\n",
    "plot_non_iid_distribution(niid_client[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "niid_skewed_clients = get_MNIST(type='non_iid_skewed', n_samples_train = num_train_samples, \n",
    "                                n_samples_test= num_test_samples, n_clients=num_clients,\n",
    "                                batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "best_params = optimize_qfed_parameters(server_model=model, clients=niid_skewed_clients)\n",
    "\n",
    "best_lr, best_q = best_params.values()\n",
    "print(best_lr, best_q)\n",
    "\n",
    "qffl_niid_model_q, qffl_niid__skewed_hist_q0 = qFed(server_model=model, clients=niid_skewed_clients,\n",
    "                                    rounds=rounds, epochs=20, learning_rate=best_lr ,q=best_q)\n",
    "\n",
    "favg_niid_skewed_model, favg_niid_skewed_hist = Fed(server_model=model, clients=niid_skewed_clients,\n",
    "                                    rounds=rounds, epochs=epochs, learning_rate=lr, type=\"avg\")\n",
    "\n",
    "losses = [favg_niid_skewed_hist.loss, qffl_niid__skewed_hist_q0.loss]\n",
    "line_names = [\"FedAvg\", \"qFedAvg(q>0)\"]\n",
    "title = \"Comparing different Fed Algorithms on IID Dataset\"\n",
    "df1 = plot_loss(losses, line_names, title)\n",
    "\n",
    "acc = [favg_niid_skewed_hist.accuracy, qffl_niid__skewed_hist_q0.accuracy]\n",
    "line_names = [\"FedAvg\", \"q-FedAvg(q>0)\"]\n",
    "title = \"Comparing different Fed Algorithms on IID Dataset\"\n",
    "df2 = plot_acc(acc, line_names, title)\n",
    "\n",
    "variance = [favg_niid_skewed_hist.variance, qffl_niid__skewed_hist_q0.variance]\n",
    "line_names = [\"FedAvg\", \"q-FedAvg(q>0)\"]\n",
    "title = \"Comparing different Fed Algorithms on IID Dataset\"\n",
    "df2 = plot_variance(variance, line_names, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "CCraYzkkruEr",
    "outputId": "73d58c41-4de4-4ff6-ad27-3151e32510eb"
   },
   "outputs": [],
   "source": [
    "qffl_iid_hist_q.variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### q = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qffl_iid_model_q, qffl_iid_hist_q5 = qFed(server_model=model, clients=iid_client,\n",
    "                                    rounds=rounds, epochs=20, learning_rate=0.1 ,q=4)\n",
    "\n",
    "losses = [favg_iid_hist.loss, qffl_iid_hist_q5.loss]\n",
    "line_names = [\"FedAvg\", \"qFedAvg(q>0)\"]\n",
    "title = \"Comparing different Fed Algorithms on IID Dataset\"\n",
    "df1 = plot_loss(losses, line_names, title)\n",
    "\n",
    "acc = [favg_iid_hist.accuracy, qffl_iid_hist_q5.accuracy]\n",
    "line_names = [\"FedAvg\", \"q-FedAvg(q>0)\"]\n",
    "title = \"Comparing different Fed Algorithms on IID Dataset\"\n",
    "df2 = plot_acc(acc, line_names, title)\n",
    "\n",
    "variance = [favg_iid_hist.variance, qffl_iid_hist_q5.variance]\n",
    "line_names = [\"FedAvg\", \"q-FedAvg(q>0)\"]\n",
    "title = \"Comparing different Fed Algorithms on IID Dataset\"\n",
    "df2 = plot_variance(variance, line_names, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qffl_iid_hist_q.variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-IID Uniform Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "favg_niid_model, favg_niid_hist = Fed(server_model=model, clients=niid_client,\n",
    "                                    rounds=rounds, epochs=epochs, learning_rate=lr, type=\"avg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "favg_niid_hist.variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### q = 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qffl_niid_model_q1, qffl_niid_hist_q1 = qFed(server_model=model, clients=niid_client,\n",
    "                                    rounds=rounds, epochs=20, learning_rate=0.1 ,q=1.5)\n",
    "\n",
    "losses = [favg_niid_hist.loss, qffl_niid_hist_q1.loss]\n",
    "line_names = [\"FedAvg\", \"qFedAvg(q>0)\"]\n",
    "title = \"Comparing different Fed Algorithms on IID Dataset\"\n",
    "df1 = plot_loss(losses, line_names, title)\n",
    "\n",
    "acc = [favg_niid_hist.accuracy, qffl_niid_hist_q1.accuracy]\n",
    "line_names = [\"FedAvg\", \"q-FedAvg(q>0)\"]\n",
    "title = \"Comparing different Fed Algorithms on IID Dataset\"\n",
    "df2 = plot_acc(acc, line_names, title)\n",
    "\n",
    "variance = [favg_niid_hist.variance, qffl_niid_hist_q1.variance]\n",
    "line_names = [\"FedAvg\", \"q-FedAvg(q>0)\"]\n",
    "title = \"Comparing different Fed Algorithms on IID Dataset\"\n",
    "df2 = plot_variance(variance, line_names, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qffl_niid_hist_q1.variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-IID Skewed Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "niid_skewed_clients = get_MNIST(type='non_iid_skewed', n_samples_train = num_train_samples, \n",
    "                                n_samples_test= num_test_samples, n_clients=num_clients,\n",
    "                                batch_size=batch_size, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "favg_niid_skewed_model, favg_niid_skewed_hist = Fed(server_model=model, clients=niid_skewed_clients,\n",
    "                                    rounds=rounds, epochs=epochs, learning_rate=lr, type=\"avg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "favg_niid_skewed_hist.variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### q = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qffl_niid_model_q, qffl_niid__skewed_hist_q0 = qFed(server_model=model, clients=niid_skewed_clients,\n",
    "                                    rounds=rounds, epochs=20, learning_rate=0.1 ,q=0)\n",
    "\n",
    "losses = [favg_niid_skewed_hist.loss, qffl_niid__skewed_hist_q0.loss]\n",
    "line_names = [\"FedAvg\", \"qFedAvg(q>0)\"]\n",
    "title = \"Comparing different Fed Algorithms on IID Dataset\"\n",
    "df1 = plot_loss(losses, line_names, title)\n",
    "\n",
    "acc = [favg_niid_skewed_hist.accuracy, qffl_niid__skewed_hist_q0.accuracy]\n",
    "line_names = [\"FedAvg\", \"q-FedAvg(q>0)\"]\n",
    "title = \"Comparing different Fed Algorithms on IID Dataset\"\n",
    "df2 = plot_acc(acc, line_names, title)\n",
    "\n",
    "variance = [favg_niid_skewed_hist.variance, qffl_niid__skewed_hist_q0.variance]\n",
    "line_names = [\"FedAvg\", \"q-FedAvg(q>0)\"]\n",
    "title = \"Comparing different Fed Algorithms on IID Dataset\"\n",
    "df2 = plot_variance(variance, line_names, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qffl_niid__skewed_hist_q0.variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### q = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qffl_niid_model_q, qffl_niid__skewed_hist_q1 = qFed(server_model=model, clients=niid_skewed_clients,\n",
    "                                    rounds=rounds, epochs=20, learning_rate=0.1 ,q=1.5)\n",
    "\n",
    "losses = [favg_niid_skewed_hist.loss, qffl_niid__skewed_hist_q1.loss]\n",
    "line_names = [\"FedAvg\", \"qFedAvg(q>0)\"]\n",
    "title = \"Comparing different Fed Algorithms on IID Dataset\"\n",
    "df1 = plot_loss(losses, line_names, title)\n",
    "\n",
    "acc = [favg_niid_skewed_hist.accuracy, qffl_niid__skewed_hist_q1.accuracy]\n",
    "line_names = [\"FedAvg\", \"q-FedAvg(q>0)\"]\n",
    "title = \"Comparing different Fed Algorithms on IID Dataset\"\n",
    "df2 = plot_acc(acc, line_names, title)\n",
    "\n",
    "variance = [favg_niid_skewed_hist.variance, qffl_niid__skewed_hist_q1.variance]\n",
    "line_names = [\"FedAvg\", \"q-FedAvg(q>0)\"]\n",
    "title = \"Comparing different Fed Algorithms on IID Dataset\"\n",
    "df2 = plot_variance(variance, line_names, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qffl_niid__skewed_hist_q1.variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### q = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qffl_niid_skewed_model_q, qffl_niid_skewed_hist_q5 = qFed(server_model=model, clients=niid_skewed_clients,\n",
    "                                    rounds=rounds, epochs=20, learning_rate=0.1 ,q=5)\n",
    "\n",
    "losses = [favg_niid_skewed_hist.loss, qffl_niid_skewed_hist_q5.loss]\n",
    "line_names = [\"FedAvg\", \"qFedAvg(q>0)\"]\n",
    "title = \"Comparing different Fed Algorithms on IID Dataset\"\n",
    "df1 = plot_loss(losses, line_names, title)\n",
    "\n",
    "acc = [favg_niid_skewed_hist.accuracy, qffl_niid_skewed_hist_q5.accuracy]\n",
    "line_names = [\"FedAvg\", \"q-FedAvg(q>0)\"]\n",
    "title = \"Comparing different Fed Algorithms on IID Dataset\"\n",
    "df2 = plot_acc(acc, line_names, title)\n",
    "\n",
    "variance = [favg_niid_skewed_hist.variance, qffl_niid_skewed_hist_q5.variance]\n",
    "line_names = [\"FedAvg\", \"q-FedAvg(q>0)\"]\n",
    "title = \"Comparing different Fed Algorithms on IID Dataset\"\n",
    "df2 = plot_variance(variance, line_names, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 708
    },
    "id": "Vo0dyB6hGyQC",
    "outputId": "16b4a826-fc84-4b81-f78a-a331e558ac2f"
   },
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 708
    },
    "id": "Ddj5G9HOGzjE",
    "outputId": "ad55812d-46af-475d-862a-1a00f133722a"
   },
   "outputs": [],
   "source": [
    "df2"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPYM6//DQjtxmH9A0xgXII2",
   "collapsed_sections": [],
   "include_colab_link": true,
   "mount_file_id": "1MzSBsuyOQjTTn7HaSfIfPLFAvKhlcrN-",
   "name": "FederatedLearning.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0d4e8c5f50b84c349d85c034fcccf499": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0d50bd19bfc14bf2b9f57c1014a8f7b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "16406388f92541d883a302f2f13b9fcf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d9dce3b52fe6441b874302ce4a530274",
      "placeholder": "​",
      "style": "IPY_MODEL_5cb3135ab32a44e0989626956d8bfbd0",
      "value": " 29696/? [00:00&lt;00:00, 7107.33it/s]"
     }
    },
    "181e3aa4062346a7a99ea80a0c01e320": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0d4e8c5f50b84c349d85c034fcccf499",
      "placeholder": "​",
      "style": "IPY_MODEL_2d363ca81d1447828a5af952a0a0d816",
      "value": ""
     }
    },
    "1dc418b8b3e74b74b8ea5dc02a48b12d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "23949ae951e1485f9fa3adfa7e66c160": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2996075ff05849d9b35e2f1aeeab782a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2d363ca81d1447828a5af952a0a0d816": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2fa22b25f2554cd98648371a1ee36f19": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d86de62e5740453284247fac415fa9c3",
      "placeholder": "​",
      "style": "IPY_MODEL_b552821412d740cca4e7cb93735fcb5c",
      "value": " 1649664/? [00:00&lt;00:00, 2739430.66it/s]"
     }
    },
    "3543fbdbb9d04ae2b0a99eccc105db66": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "37c752ef30e7422ab7c81e08a561af47": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "431b924395cd480ca4b910d239547871": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "47e8d63034cd45308a065d138468dac7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4c58dae243554c46a25f4be58bf887a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_741762232f394a5bb08d394234dd016c",
       "IPY_MODEL_5ce35183b9f34799a93be7e9c88edf47",
       "IPY_MODEL_c5c4f8289da844f7b58ccb698709f70e"
      ],
      "layout": "IPY_MODEL_e979eb222e724a8f914aea3b8273efa4"
     }
    },
    "4ce5a57d913b4cee9f023eabaebe3c91": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_558a63cdf465494ebc0f02cd530daf19",
       "IPY_MODEL_f07cdd1bb93440a0a75f0cb8fe1f7a0d",
       "IPY_MODEL_2fa22b25f2554cd98648371a1ee36f19"
      ],
      "layout": "IPY_MODEL_650eb647f75f4818b65d2a5a2560e63d"
     }
    },
    "556274a6447d43a998a0f76bbfe7f7ca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "558a63cdf465494ebc0f02cd530daf19": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6ba5b9b3f5404af8ba23059e920907dd",
      "placeholder": "​",
      "style": "IPY_MODEL_eba170fbd76c4b09af8b6ef333c10ba7",
      "value": ""
     }
    },
    "5cb3135ab32a44e0989626956d8bfbd0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5cb54245865a4756bf36ff974c9d58b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2996075ff05849d9b35e2f1aeeab782a",
      "max": 28881,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_70d0223b99974b5a835426ae83290680",
      "value": 28881
     }
    },
    "5ce35183b9f34799a93be7e9c88edf47": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3543fbdbb9d04ae2b0a99eccc105db66",
      "max": 9912422,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c65d30fb86954a5e8e6fbdf2e687fdd5",
      "value": 9912422
     }
    },
    "650eb647f75f4818b65d2a5a2560e63d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6902054c7f634fa096f6c7fec81957c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6ba5b9b3f5404af8ba23059e920907dd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6da43a5f9bd148c9844623fb118e2a41": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_181e3aa4062346a7a99ea80a0c01e320",
       "IPY_MODEL_c6d8e41521be44239755e556f68661f3",
       "IPY_MODEL_8d277fee9e60474aafeaea502a0fd102"
      ],
      "layout": "IPY_MODEL_37c752ef30e7422ab7c81e08a561af47"
     }
    },
    "70d0223b99974b5a835426ae83290680": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "741762232f394a5bb08d394234dd016c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_431b924395cd480ca4b910d239547871",
      "placeholder": "​",
      "style": "IPY_MODEL_6902054c7f634fa096f6c7fec81957c6",
      "value": ""
     }
    },
    "7d2638141f844805982a037cfe00d065": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8d277fee9e60474aafeaea502a0fd102": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_556274a6447d43a998a0f76bbfe7f7ca",
      "placeholder": "​",
      "style": "IPY_MODEL_47e8d63034cd45308a065d138468dac7",
      "value": " 5120/? [00:00&lt;00:00, 6656.10it/s]"
     }
    },
    "a4d3281bf34144ffb732dac0f253e3f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_acc1455bae7f4fd2bf5f61fb1b75f867",
       "IPY_MODEL_5cb54245865a4756bf36ff974c9d58b3",
       "IPY_MODEL_16406388f92541d883a302f2f13b9fcf"
      ],
      "layout": "IPY_MODEL_b24725b3b4c141b38eebe6bca56439b6"
     }
    },
    "acc1455bae7f4fd2bf5f61fb1b75f867": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_23949ae951e1485f9fa3adfa7e66c160",
      "placeholder": "​",
      "style": "IPY_MODEL_fa07f9ea000b4e55ba29834ede2b71d6",
      "value": ""
     }
    },
    "b24725b3b4c141b38eebe6bca56439b6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b552821412d740cca4e7cb93735fcb5c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c5c4f8289da844f7b58ccb698709f70e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1dc418b8b3e74b74b8ea5dc02a48b12d",
      "placeholder": "​",
      "style": "IPY_MODEL_cb280b2482d9468682aa2281321a7586",
      "value": " 9913344/? [00:00&lt;00:00, 20663101.24it/s]"
     }
    },
    "c65d30fb86954a5e8e6fbdf2e687fdd5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c68ceec27cc94e2f9ad531eb9dca7261": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c6d8e41521be44239755e556f68661f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c68ceec27cc94e2f9ad531eb9dca7261",
      "max": 4542,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0d50bd19bfc14bf2b9f57c1014a8f7b5",
      "value": 4542
     }
    },
    "cb280b2482d9468682aa2281321a7586": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d07c6cc1d5c8498785b65b33b4693656": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d86de62e5740453284247fac415fa9c3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d9dce3b52fe6441b874302ce4a530274": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e979eb222e724a8f914aea3b8273efa4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eba170fbd76c4b09af8b6ef333c10ba7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f07cdd1bb93440a0a75f0cb8fe1f7a0d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7d2638141f844805982a037cfe00d065",
      "max": 1648877,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d07c6cc1d5c8498785b65b33b4693656",
      "value": 1648877
     }
    },
    "fa07f9ea000b4e55ba29834ede2b71d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
